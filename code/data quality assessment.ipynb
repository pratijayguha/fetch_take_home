{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Assessment Notebook\n",
    "\n",
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import commons\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Pandas Variables\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 40)\n",
    "\n",
    "# Save location for plots\n",
    "USERS_NULL_PCT_CHART_PATH = os.path.join(\n",
    "    commons.PLOTS_PATH, \"null_percentages\", \"users.png\"\n",
    ")\n",
    "TRANSACTIONS_NULL_PCT_CHART_PATH = os.path.join(\n",
    "    commons.PLOTS_PATH, \"null_percentages\", \"transactions.png\"\n",
    ")\n",
    "PRODUCTS_NULL_PCT_CHART_PATH = os.path.join(\n",
    "    commons.PLOTS_PATH, \"null_percentages\", \"products.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Data files\n",
    "products = pd.read_parquet(commons.PRODUCTS_CLEAN_PARQUET_PATH)\n",
    "users = pd.read_parquet(commons.USERS_CLEAN_PARQUET_PATH)\n",
    "transactions = pd.read_parquet(commons.TRANSACTIONS_CLEAN_PARQUET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Overview \n",
    "This notebook analyzes data quality across three key datasets:\n",
    "- Products table\n",
    "- Users table  \n",
    "- Transactions table\n",
    "\n",
    "### 2.1 Missing Data Analysis\n",
    "The below code examines missing values and their distributions across all three tables. The results here are discussed in Section 3.2 in the Quality Analysis doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful functions\n",
    "def get_null_counts(df: pd.DataFrame):\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"column\": df.columns,\n",
    "            \"null_count\": df.isnull().sum(),\n",
    "            \"non_null_count\": df.notnull().sum(),\n",
    "        }\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def plot_null_percentages(df: pd.DataFrame):\n",
    "    # Calculate percentages\n",
    "    df_sorted = df.sort_values(\"null_count\", ascending=False)\n",
    "    total = df_sorted[\"null_count\"] + df_sorted[\"non_null_count\"]\n",
    "    df_sorted[\"null_pct\"] = (df_sorted[\"null_count\"] / total * 100).round(1)\n",
    "    df_sorted[\"non_null_pct\"] = (df_sorted[\"non_null_count\"] / total * 100).round(1)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    sns.barplot(x=\"column\", y=\"null_pct\", data=df_sorted, color=\"red\", label=\"Null %\")\n",
    "    sns.barplot(\n",
    "        x=\"column\",\n",
    "        y=\"non_null_pct\",\n",
    "        data=df_sorted,\n",
    "        color=\"green\",\n",
    "        label=\"Non-Null %\",\n",
    "        bottom=df_sorted[\"null_pct\"],\n",
    "    )\n",
    "\n",
    "    # Add percentage labels\n",
    "    for i, pct in enumerate(df_sorted[\"null_pct\"]):\n",
    "        plt.text(i, 50, f\"{pct}%\", ha=\"center\", va=\"center\")\n",
    "\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.xlabel(\"Column Names\")\n",
    "    plt.ylabel(\"Percentage (%)\")\n",
    "    plt.ylim(0, 100)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    return plt\n",
    "\n",
    "\n",
    "# === Code ===\n",
    "products_nulls = get_null_counts(products)\n",
    "users_nulls = get_null_counts(users)\n",
    "transactions_nulls = get_null_counts(transactions)\n",
    "\n",
    "plot = plot_null_percentages(transactions_nulls)\n",
    "plot.title(\"Transactions Table\")\n",
    "plot.savefig(TRANSACTIONS_NULL_PCT_CHART_PATH, dpi=300, format=\"png\")\n",
    "\n",
    "plot = plot_null_percentages(users_nulls)\n",
    "plot.title(\"Users Table\")\n",
    "plot.savefig(USERS_NULL_PCT_CHART_PATH, dpi=300, format=\"png\")\n",
    "\n",
    "plot = plot_null_percentages(products_nulls)\n",
    "plot.title(\"Products Table\")  # MIs\n",
    "plot.savefig(PRODUCTS_NULL_PCT_CHART_PATH, dpi=300, format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data Integrity Analysis\n",
    "\n",
    "#### 2.3.1 Duplicate Entries \n",
    "Identifies completely duplicate rows in each table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful functions\n",
    "def get_num_redundant_rows(df: pd.DataFrame, pk_col: str):\n",
    "    duplicate_rows = df[df.duplicated(keep=False)]\n",
    "    # Calculate metrics\n",
    "    unique_dupl_rows = len(duplicate_rows[pk_col].unique())\n",
    "    total_duplicate_rows = len(duplicate_rows)\n",
    "    return total_duplicate_rows - unique_dupl_rows\n",
    "\n",
    "\n",
    "# === Code ===\n",
    "print(\n",
    "    \"Redundant rows in {0}: {1}\".format(\n",
    "        \"transactions\", get_num_redundant_rows(transactions, \"RECEIPT_ID\")\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Redundant rows in {0}: {1}\".format(\n",
    "        \"products\", get_num_redundant_rows(products, \"BARCODE\")\n",
    "    )\n",
    ")\n",
    "print(\"Redundant rows in {0}: {1}\".format(\"users\", get_num_redundant_rows(users, \"ID\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Inconsistent Entries\n",
    "This analysis identifies records where the same key value (e.g., BARCODE, USER_ID, RECEIPT_ID) appears multiple times but with different values in other columns. These are different from pure duplicates because some data fields don't match.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful functions\n",
    "def get_inconsistent_entries(df: pd.DataFrame, pk_col: str):\n",
    "    clean_df = df[df[pk_col].notna()].copy()\n",
    "    duplicate_mask = clean_df.duplicated(subset=[pk_col], keep=False)\n",
    "    inconsistent_entries = clean_df[duplicate_mask].sort_values(pk_col)\n",
    "    return inconsistent_entries.sort_values(by=pk_col)\n",
    "\n",
    "\n",
    "# === Code ===\n",
    "products_inconsistent = get_inconsistent_entries(products, \"BARCODE\")\n",
    "users_inconsistent = get_inconsistent_entries(users, \"ID\")\n",
    "transactions_inconsistent = get_inconsistent_entries(transactions, \"RECEIPT_ID\")\n",
    "\n",
    "print(\n",
    "    \"Number of inconsistent records in {0}: {1}\".format(\n",
    "        \"products\", len(products_inconsistent)\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Number of inconsistent records in {0}: {1}\".format(\n",
    "        \"transactions\", len(transactions_inconsistent)\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Number of inconsistent records in {0}: {1}\".format(\n",
    "        \"users\", len(users_inconsistent)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Data Reference Analysis\n",
    "\n",
    "#### 2.4.1 Barcode Reference Check\n",
    "This analysis examines referential integrity between transactions and products tables by validating barcode relationships.\n",
    "\n",
    "**Purpose:**\n",
    "- Verify that every barcode in transactions table has a corresponding entry in products table\n",
    "- Identify orphaned transactions (those with barcodes not found in products)\n",
    "- Calculate the percentage of transactions with invalid barcode references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nulls from `BARCODE`\n",
    "cleaned_transactions = transactions[transactions[\"BARCODE\"].notna()].copy()\n",
    "\n",
    "# Find barcodes in transactions that don't exist in products catalog\n",
    "missing_barcodes = cleaned_transactions[\n",
    "    ~cleaned_transactions[\"BARCODE\"].isin(products[\"BARCODE\"])\n",
    "]\n",
    "\n",
    "# Get unique counts for calculation\n",
    "unique_barcodes = cleaned_transactions[\"BARCODE\"].unique()\n",
    "unique_missing_barcodes = missing_barcodes[\"BARCODE\"].unique()\n",
    "\n",
    "# Print summary\n",
    "print(f\"Total missing barcodes: {len(unique_barcodes)}\")\n",
    "print(\n",
    "    f\"Percentage missing: {(len(unique_missing_barcodes)/len(unique_barcodes))*100:.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 User Reference Check\n",
    "\n",
    "Analyzes referential integrity between transactions and users tables by verifying user ID relationships.\n",
    "\n",
    "**Purpose:**\n",
    "- Verify that every `USER_ID` in `transactions` table has a corresponding entry in `users` table\n",
    "- Identify orphaned users (those with barcodes not found in `users`)\n",
    "- Calculate the percentage of transactions with invalid barcode references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find IDs in transactions that don't exist in users table \n",
    "missing_users = transactions[~transactions[\"USER_ID\"].isin(users[\"ID\"])][\n",
    "   \"USER_ID\"\n",
    "].unique()\n",
    "\n",
    "# Get count of all unique users in transactions\n",
    "unique_users = transactions[\"USER_ID\"].unique()\n",
    "\n",
    "# Print summary stats\n",
    "print(f\"Total missing users: {len(missing_users)}\")\n",
    "print(f\"Percentage missing: {(len(missing_users)/len(unique_users))*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4 Data Validation Anomalies \n",
    "\n",
    "Checks for records that violate basic business logic - in this case, transactions where receipt was scanned before purchase date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3.4. Validation Issues\n",
    "print(\n",
    "    \"Number of records in transactions where `SCAN_DATE` < 'PURCHASE_DATE`: {}\".format(\n",
    "        len(transactions[transactions[\"SCAN_DATE\"] < transactions[\"PURCHASE_DATE\"]])\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
